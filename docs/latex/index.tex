\subsection*{Feature\+:}

\subsubsection*{Python x C++}

Benefit from both side. One can do simple prototype on python side and easy transfer to C++ with small effort!


\begin{DoxyCode}
\textcolor{comment}{// c++ version:}
\textcolor{preprocessor}{#include "cytnx.hpp"}
\hyperlink{classcytnx_1_1Tensor}{cytnx::Tensor} A(\{3,4,5\},cytnx::Type.Double,cytnx::Device.cpu)
\end{DoxyCode}



\begin{DoxyCode}
\textcolor{comment}{# python version:}
\textcolor{keyword}{import} cytnx
A =  \hyperlink{classcytnx_1_1Tensor}{cytnx.Tensor}([3,4,5],dtype=cytnx.Type.Double,device=cytnx.Device.cpu)
\end{DoxyCode}


\subsubsection*{1. All the Storage and Tensor can now have mulitple type support.}

The avaliable types are \+:

\tabulinesep=1mm
\begin{longtabu} spread 0pt [c]{*{3}{|X[-1]}|}
\hline
\rowcolor{\tableheadbgcolor}\textbf{ cytnx type }&\textbf{ c++ type }&\textbf{ Type object  }\\\cline{1-3}
\endfirsthead
\hline
\endfoot
\hline
\rowcolor{\tableheadbgcolor}\textbf{ cytnx type }&\textbf{ c++ type }&\textbf{ Type object  }\\\cline{1-3}
\endhead
cytnx\+\_\+double &double &Type.\+Double \\\cline{1-3}
cytnx\+\_\+float &float &Type.\+Float \\\cline{1-3}
cytnx\+\_\+uint64 &uint64\+\_\+t &Type.\+Uint64 \\\cline{1-3}
cytnx\+\_\+uint32 &uint32\+\_\+t &Type.\+Uint32 \\\cline{1-3}
cytnx\+\_\+int64 &int64\+\_\+t &Type.\+Int64 \\\cline{1-3}
cytnx\+\_\+int32 &int32\+\_\+t &Type.\+Int32 \\\cline{1-3}
cytnx\+\_\+complex128 &std\+::complex$<$double$>$ &Type.\+Complex\+Double \\\cline{1-3}
cytnx\+\_\+complex64 &std\+::complex$<$float$>$ &Type.\+Complex\+Float \\\cline{1-3}
\end{longtabu}
\subsubsection*{2. Multiple devices support.}


\begin{DoxyItemize}
\item simple moving btwn C\+PU and G\+PU (see below)
\end{DoxyItemize}

\subsection*{Objects\+:}


\begin{DoxyItemize}
\item \hyperlink{classcytnx_1_1Storage}{Storage } \mbox{[}binded\mbox{]}
\item \hyperlink{classcytnx_1_1Tensor}{Tensor } \mbox{[}binded\mbox{]}
\item \hyperlink{classcytnx_1_1Bond}{Bond } \mbox{[}binded\mbox{]}
\item \hyperlink{classcytnx_1_1Accessor}{Accessor } \mbox{[}c++ only\mbox{]}
\item \hyperlink{classcytnx_1_1Symmetry}{Symmetry } \mbox{[}binded\mbox{]}
\item \hyperlink{classcytnx_1_1UniTensor}{Uni\+Tensor } \mbox{[}binded\mbox{]}
\end{DoxyItemize}

\subsection*{linear algebra functions\+:}

See \hyperlink{namespacecytnx_1_1linalg}{cytnx\+::linalg } for further details

\tabulinesep=1mm
\begin{longtabu} spread 0pt [c]{*{5}{|X[-1]}|}
\hline
\rowcolor{\tableheadbgcolor}\textbf{ func }&\textbf{ inplace }&\textbf{ C\+PU }&\textbf{ G\+PU }&\textbf{ callby tn  }\\\cline{1-5}
\endfirsthead
\hline
\endfoot
\hline
\rowcolor{\tableheadbgcolor}\textbf{ func }&\textbf{ inplace }&\textbf{ C\+PU }&\textbf{ G\+PU }&\textbf{ callby tn  }\\\cline{1-5}
\endhead
\hyperlink{namespacecytnx_1_1linalg_af36e9e20e4c7d74f2f6f838902482d98}{Add} &x &Y &Y &Y \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_a78477b25b3eed121847f1a13b878a925}{Sub} &x &Y &Y &Y \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_a2fc49876b7b53f6f6e97ce70f475f636}{Mul} &x &Y &Y &Y \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_abc1940e0e7364299ea1481c81003ba13}{Div} &x &Y &Y &Y \\\cline{1-5}
+,+=\mbox{[}tn\mbox{]}&x &Y &Y &Y (\hyperlink{}{Tensor.\+Add\+\_\+}) \\\cline{1-5}
-\/,-\/=\mbox{[}tn\mbox{]}&x &Y &Y &Y (\hyperlink{}{Tensor.\+Sub\+\_\+}) \\\cline{1-5}
$\ast$,$\ast$=\mbox{[}tn\mbox{]}&x &Y &Y &Y (\hyperlink{}{Tensor.\+Mul\+\_\+}) \\\cline{1-5}
/,/=\mbox{[}tn\mbox{]}&x &Y &Y &Y (\hyperlink{}{Tensor.\+Div\+\_\+}) \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_ac17f16959a4849ea91bce712d24d4e4e}{Svd} &x &Y &Y &Y \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_a351ad02f478ba8082ee79a37a2a8f108}{Inv} &\hyperlink{namespacecytnx_1_1linalg_a26628db51e90867ddc050ab11a317a8d}{Inv\+\_\+} &Y &Y &Y \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_a470d0886432554a35ecaf961451c0806}{Conj} &\hyperlink{namespacecytnx_1_1linalg_adc3233bf8bc3eb6a435340f912412801}{Conj\+\_\+} &Y &Y &Y \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_aac38382cbc0e8202411c96a0ff636471}{Exp} &\hyperlink{namespacecytnx_1_1linalg_aaab08439dde94ee87939d07933ede6e3}{Exp\+\_\+} &Y &Y &Y \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_aa9f11ed24ef9684fb8d05c228e3852d6}{Eigh} &x &Y &Y &Y \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_a53feb441b4b1bd263714ed33e093728f}{Matmul} &x &Y &Y &N \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_a5913f0bdd6cc130aeb927f42a874a149}{Diag} &x &Y &Y &N \\\cline{1-5}
$\ast$\hyperlink{namespacecytnx_1_1linalg_a460e44db6b3d5d2c30c2d2723ff8f788}{Tensordot} &x &Y &Y &N \\\cline{1-5}
\hyperlink{namespacecytnx_1_1linalg_ac76f4b5f153cdc817de5d33240046e52}{Otimes} &x &Y &Y &N \\\cline{1-5}
\end{longtabu}
$\ast$this is a high level linalg

\subsection*{Generators}

Tensor\+: \hyperlink{namespacecytnx_ab8a79a03fb0465f3eb2641017f3f1755}{zeros()}, ones(), arange()

\subsection*{Requirements}


\begin{DoxyItemize}
\item Boost v1.\+53+ \mbox{[}check\+\_\+deleted, atomicadd, intrusive\+\_\+ptr\mbox{]}
\item C++11
\item lapack
\item blas
\item gcc v6+
\end{DoxyItemize}

\mbox{[}C\+U\+DA support\mbox{]}
\begin{DoxyItemize}
\item C\+U\+DA v10+
\item cu\+D\+NN
\end{DoxyItemize}

\mbox{[}Open\+Mp support\mbox{]}
\begin{DoxyItemize}
\item openmp
\end{DoxyItemize}

\mbox{[}Python\mbox{]}
\begin{DoxyItemize}
\item pybind11 2.\+2.\+4
\item numpy $>$= 1.\+15
\end{DoxyItemize}

\subsection*{compile}


\begin{DoxyItemize}
\item compile\+:

\$make -\/\+Bj4
\item turn on D\+E\+B\+UG mode\+:

\$make -\/\+Bj4 D\+E\+B\+U\+G\+\_\+\+Enable=1
\item turn on Open\+Mp accelerate

\$make -\/\+Bj4 O\+M\+P\+\_\+\+Enable=1
\item turn on G\+PU accelerate

\$make -\/\+Bj4 G\+P\+U\+\_\+\+Enable=1
\item turn on G\+P\+U+\+Open\+Mp accelerate

\$make -\/\+Bj4 G\+P\+U\+\_\+\+Enable=1 O\+M\+P\+\_\+\+Enable=1
\item compile python wrapper

\$make pyobj -\/\+Bj4 $<$args$>$
\end{DoxyItemize}

$<$args$>$ can be O\+M\+P\+\_\+\+Enable, G\+P\+U\+\_\+\+Enable, D\+E\+B\+U\+G\+\_\+\+Enable, M\+K\+L\+\_\+\+Enable.

Note\+: if M\+K\+L\+\_\+\+Enable=1, will enforce using icpc as compiler.

\subsection*{Some snippets\+:}

\subsubsection*{Storage}


\begin{DoxyItemize}
\item Memory container with G\+P\+U/\+C\+PU support. maintain type conversions (type casting btwn Storages) and moving btwn devices.
\item Generic type object, the behavior is very similar to python. 
\begin{DoxyCode}
Storage A(400,Type.Double);
\textcolor{keywordflow}{for}(\textcolor{keywordtype}{int} i=0;i<400;i++)
    A.at<\textcolor{keywordtype}{double}>(i) = i;

Storage B = A; \textcolor{comment}{// A and B share same memory, this is similar as python }

Storage C = A.to(Device.cuda+0); 
\end{DoxyCode}

\end{DoxyItemize}

\subsubsection*{Tensor}


\begin{DoxyItemize}
\item A tensor, A\+PI very similar to numpy and pytorch.
\item simple moving btwn C\+PU and G\+PU\+: 
\begin{DoxyCode}
Tensor A(\{3,4\},Type.Double,Device.cpu); \textcolor{comment}{// create tensor on CPU (default)}
Tensor B(\{3,4\},Type.Double,Device.cuda+0); \textcolor{comment}{// create tensor on GPU with gpu-id=0}


Tensor C = B; \textcolor{comment}{// C and B share same memory.}

\textcolor{comment}{// move A to gpu}
Tensor D = A.to(Device.cuda+0);

\textcolor{comment}{// inplace move A to gpu}
A.to\_(Device.cuda+0);
\end{DoxyCode}

\item Type conversion in between avaliable\+: 
\begin{DoxyCode}
Tensor A(\{3,4\},Type.Double);
Tensor B = A.astype(Type.Uint64); \textcolor{comment}{// cast double to uint64\_t}
\end{DoxyCode}

\item vitual swap and permute. All the permute and swap will not change the underlying memory
\item Use Contiguous() when needed to actual moving the memory layout. 
\begin{DoxyCode}
Tensor A(\{3,4,5,2\},Type.Double);
A.permute\_(\{0,3,1,2\}); \textcolor{comment}{// this will not change the memory, only the shape info is changed.}
cout << A.is\_contiguous() << endl; \textcolor{comment}{// this will be false!}

A.contiguous\_(); \textcolor{comment}{// call Configuous() to actually move the memory.}
cout << A.is\_contiguous() << endl; \textcolor{comment}{// this will be true!}
\end{DoxyCode}

\item access single element using .at 
\begin{DoxyCode}
Tensor A(\{3,4,5\},Type.Double);
\textcolor{keywordtype}{double} val = A.at<\textcolor{keywordtype}{double}>(\{0,2,2\});
\end{DoxyCode}

\item access elements with python slices similarity\+: 
\begin{DoxyCode}
\textcolor{keyword}{typedef} Accessor ac;
Tensor A(\{3,4,5\},Type.Double);
Tensor out = A.get(\{ac(0),ac::all(),ac::range(1,4)\}); 
\textcolor{comment}{// equivalent to python: out = A[0,:,1:4]    }
\end{DoxyCode}

\end{DoxyItemize}

\subsection*{Fast Examples}

\begin{DoxyVerb}See test.cpp for using C++ .
See test.py for using python  
\end{DoxyVerb}


\subsection*{Developer}

\begin{DoxyVerb}Kai-Hsin Wu kaihsinwu@gmail.com \end{DoxyVerb}
 