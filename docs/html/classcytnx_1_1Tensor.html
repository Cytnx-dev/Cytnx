<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Cytnx: cytnx::Tensor Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="Icon_small.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Cytnx
   &#160;<span id="projectnumber">v0.0.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecytnx.html">cytnx</a></li><li class="navelem"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classcytnx_1_1Tensor-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cytnx::Tensor Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>an tensor (multi-dimensional array)  
 <a href="classcytnx_1_1Tensor.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="Tensor_8hpp_source.html">Tensor.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a4472af6f8e825a13440e832bf82fb627"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a4472af6f8e825a13440e832bf82fb627">dtype</a> () const</td></tr>
<tr class="memdesc:a4472af6f8e825a13440e832bf82fb627"><td class="mdescLeft">&#160;</td><td class="mdescRight">the dtype-id of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>  <a href="#a4472af6f8e825a13440e832bf82fb627">More...</a><br /></td></tr>
<tr class="separator:a4472af6f8e825a13440e832bf82fb627"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6d3310eb4defbdacf662dcd81d8fe09"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#ac6d3310eb4defbdacf662dcd81d8fe09">device</a> () const</td></tr>
<tr class="memdesc:ac6d3310eb4defbdacf662dcd81d8fe09"><td class="mdescLeft">&#160;</td><td class="mdescRight">the device-id of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>  <a href="#ac6d3310eb4defbdacf662dcd81d8fe09">More...</a><br /></td></tr>
<tr class="separator:ac6d3310eb4defbdacf662dcd81d8fe09"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e09106c7529e8be90caa52e1541e498"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a9e09106c7529e8be90caa52e1541e498">dtype_str</a> () const</td></tr>
<tr class="memdesc:a9e09106c7529e8be90caa52e1541e498"><td class="mdescLeft">&#160;</td><td class="mdescRight">the dtype (in string) of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>  <a href="#a9e09106c7529e8be90caa52e1541e498">More...</a><br /></td></tr>
<tr class="separator:a9e09106c7529e8be90caa52e1541e498"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a335f7625fa01784f49b2223238d0c14e"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a335f7625fa01784f49b2223238d0c14e">device_str</a> () const</td></tr>
<tr class="memdesc:a335f7625fa01784f49b2223238d0c14e"><td class="mdescLeft">&#160;</td><td class="mdescRight">the device (in string) of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>  <a href="#a335f7625fa01784f49b2223238d0c14e">More...</a><br /></td></tr>
<tr class="separator:a335f7625fa01784f49b2223238d0c14e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d0ab6d09633ad4d6099aa822ec5335a"><td class="memItemLeft" align="right" valign="top">const std::vector&lt; cytnx_uint64 &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a> () const</td></tr>
<tr class="memdesc:a6d0ab6d09633ad4d6099aa822ec5335a"><td class="mdescLeft">&#160;</td><td class="mdescRight">the shape of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>  <a href="#a6d0ab6d09633ad4d6099aa822ec5335a">More...</a><br /></td></tr>
<tr class="separator:a6d0ab6d09633ad4d6099aa822ec5335a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e2248e9babdb786167ed349df9084ae"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a5e2248e9babdb786167ed349df9084ae">clone</a> () const</td></tr>
<tr class="memdesc:a5e2248e9babdb786167ed349df9084ae"><td class="mdescLeft">&#160;</td><td class="mdescRight">return a clone of the current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.  <a href="#a5e2248e9babdb786167ed349df9084ae">More...</a><br /></td></tr>
<tr class="separator:a5e2248e9babdb786167ed349df9084ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf7f697a9434f9bc98a7d00a555ee982"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#acf7f697a9434f9bc98a7d00a555ee982">to</a> (const int &amp;<a class="el" href="classcytnx_1_1Tensor.html#ac6d3310eb4defbdacf662dcd81d8fe09">device</a>) const</td></tr>
<tr class="memdesc:acf7f697a9434f9bc98a7d00a555ee982"><td class="mdescLeft">&#160;</td><td class="mdescRight">copy a tensor to new device  <a href="#acf7f697a9434f9bc98a7d00a555ee982">More...</a><br /></td></tr>
<tr class="separator:acf7f697a9434f9bc98a7d00a555ee982"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a114a31fbb8bf4a90f150b6a67e42183a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a114a31fbb8bf4a90f150b6a67e42183a">to_</a> (const int &amp;<a class="el" href="classcytnx_1_1Tensor.html#ac6d3310eb4defbdacf662dcd81d8fe09">device</a>)</td></tr>
<tr class="memdesc:a114a31fbb8bf4a90f150b6a67e42183a"><td class="mdescLeft">&#160;</td><td class="mdescRight">move the current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> to the device.  <a href="#a114a31fbb8bf4a90f150b6a67e42183a">More...</a><br /></td></tr>
<tr class="separator:a114a31fbb8bf4a90f150b6a67e42183a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a1d9ed962b0e9a484e2bb0de15eb76d"><td class="memItemLeft" align="right" valign="top"><a id="a6a1d9ed962b0e9a484e2bb0de15eb76d"></a>
const bool &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>is_contiguous</b> () const</td></tr>
<tr class="separator:a6a1d9ed962b0e9a484e2bb0de15eb76d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18f27d1fff73e4fb4109bc8faf3b5ace"><td class="memItemLeft" align="right" valign="top"><a id="a18f27d1fff73e4fb4109bc8faf3b5ace"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>permute_</b> (const std::vector&lt; cytnx_uint64 &gt; &amp;rnks)</td></tr>
<tr class="separator:a18f27d1fff73e4fb4109bc8faf3b5ace"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbdc402a8c4d6d738523a888bcf9c0c2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#adbdc402a8c4d6d738523a888bcf9c0c2">permute</a> (const std::vector&lt; cytnx_uint64 &gt; &amp;rnks) const</td></tr>
<tr class="memdesc:adbdc402a8c4d6d738523a888bcf9c0c2"><td class="mdescLeft">&#160;</td><td class="mdescRight">perform tensor permute on the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">cytnx::Tensor</a> and return a new instance.  <a href="#adbdc402a8c4d6d738523a888bcf9c0c2">More...</a><br /></td></tr>
<tr class="separator:adbdc402a8c4d6d738523a888bcf9c0c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a127e50508e1ee0eadf11601d66d76988"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a127e50508e1ee0eadf11601d66d76988">contiguous</a> ()</td></tr>
<tr class="memdesc:a127e50508e1ee0eadf11601d66d76988"><td class="mdescLeft">&#160;</td><td class="mdescRight">Make the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> contiguous by coalescing the memory (storage).  <a href="#a127e50508e1ee0eadf11601d66d76988">More...</a><br /></td></tr>
<tr class="separator:a127e50508e1ee0eadf11601d66d76988"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a405470654ef4ef5fc0b1d24754a3daf9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a405470654ef4ef5fc0b1d24754a3daf9">contiguous_</a> ()</td></tr>
<tr class="memdesc:a405470654ef4ef5fc0b1d24754a3daf9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Make the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> contiguous by coalescing the memory (storage), inplacely.  <a href="#a405470654ef4ef5fc0b1d24754a3daf9">More...</a><br /></td></tr>
<tr class="separator:a405470654ef4ef5fc0b1d24754a3daf9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3723449528b9a20dd46c32c9e042b8f0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a3723449528b9a20dd46c32c9e042b8f0">reshape_</a> (const std::vector&lt; cytnx_int64 &gt; &amp;new_shape)</td></tr>
<tr class="memdesc:a3723449528b9a20dd46c32c9e042b8f0"><td class="mdescLeft">&#160;</td><td class="mdescRight">reshape the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>, inplacely  <a href="#a3723449528b9a20dd46c32c9e042b8f0">More...</a><br /></td></tr>
<tr class="separator:a3723449528b9a20dd46c32c9e042b8f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a182f8f7b3ae3d0db8ed55d2adf8c6b45"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a182f8f7b3ae3d0db8ed55d2adf8c6b45">reshape</a> (const std::vector&lt; cytnx_int64 &gt; &amp;new_shape)</td></tr>
<tr class="memdesc:a182f8f7b3ae3d0db8ed55d2adf8c6b45"><td class="mdescLeft">&#160;</td><td class="mdescRight">return a new <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> that is reshaped.  <a href="#a182f8f7b3ae3d0db8ed55d2adf8c6b45">More...</a><br /></td></tr>
<tr class="separator:a182f8f7b3ae3d0db8ed55d2adf8c6b45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b996d3281e7375b29a7cfe4273b299f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a7b996d3281e7375b29a7cfe4273b299f">astype</a> (const int &amp;new_type) const</td></tr>
<tr class="memdesc:a7b996d3281e7375b29a7cfe4273b299f"><td class="mdescLeft">&#160;</td><td class="mdescRight">return a new <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> that cast to different dtype.  <a href="#a7b996d3281e7375b29a7cfe4273b299f">More...</a><br /></td></tr>
<tr class="separator:a7b996d3281e7375b29a7cfe4273b299f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a697b114d1df390ca558ea9211c2d683b"><td class="memTemplParams" colspan="2">template&lt;class T &gt; </td></tr>
<tr class="memitem:a697b114d1df390ca558ea9211c2d683b"><td class="memTemplItemLeft" align="right" valign="top">T &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a697b114d1df390ca558ea9211c2d683b">at</a> (const std::vector&lt; cytnx_uint64 &gt; &amp;locator)</td></tr>
<tr class="memdesc:a697b114d1df390ca558ea9211c2d683b"><td class="mdescLeft">&#160;</td><td class="mdescRight">[C++ only] get an element at specific location.  <a href="#a697b114d1df390ca558ea9211c2d683b">More...</a><br /></td></tr>
<tr class="separator:a697b114d1df390ca558ea9211c2d683b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b686c6641c3c1eeb2d34cb7c09e433b"><td class="memTemplParams" colspan="2">template&lt;class T &gt; </td></tr>
<tr class="memitem:a7b686c6641c3c1eeb2d34cb7c09e433b"><td class="memTemplItemLeft" align="right" valign="top">T &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a7b686c6641c3c1eeb2d34cb7c09e433b">item</a> ()</td></tr>
<tr class="memdesc:a7b686c6641c3c1eeb2d34cb7c09e433b"><td class="mdescLeft">&#160;</td><td class="mdescRight">get an from a rank-0 <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>  <a href="#a7b686c6641c3c1eeb2d34cb7c09e433b">More...</a><br /></td></tr>
<tr class="separator:a7b686c6641c3c1eeb2d34cb7c09e433b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad7b928e4cb89d40cbd99aefab9aa0075"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#ad7b928e4cb89d40cbd99aefab9aa0075">get</a> (const std::vector&lt; <a class="el" href="classcytnx_1_1Accessor.html">cytnx::Accessor</a> &gt; &amp;accessors) const</td></tr>
<tr class="memdesc:ad7b928e4cb89d40cbd99aefab9aa0075"><td class="mdescLeft">&#160;</td><td class="mdescRight">get elements using <a class="el" href="classcytnx_1_1Accessor.html" title="object that mimic the python slice to access elements in C++ [this is for c++ API only]...">Accessor</a> (C++ API) / slices (python API)  <a href="#ad7b928e4cb89d40cbd99aefab9aa0075">More...</a><br /></td></tr>
<tr class="separator:ad7b928e4cb89d40cbd99aefab9aa0075"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a771f1f5b51f89abd8df4166e602214ac"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a771f1f5b51f89abd8df4166e602214ac">set</a> (const std::vector&lt; <a class="el" href="classcytnx_1_1Accessor.html">cytnx::Accessor</a> &gt; &amp;accessors, const <a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;rhs)</td></tr>
<tr class="memdesc:a771f1f5b51f89abd8df4166e602214ac"><td class="mdescLeft">&#160;</td><td class="mdescRight">set elements with the input <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> using <a class="el" href="classcytnx_1_1Accessor.html" title="object that mimic the python slice to access elements in C++ [this is for c++ API only]...">Accessor</a> (C++ API) / slices (python API)  <a href="#a771f1f5b51f89abd8df4166e602214ac">More...</a><br /></td></tr>
<tr class="separator:a771f1f5b51f89abd8df4166e602214ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad93d654b978add6b2f0dfb9f91490209"><td class="memTemplParams" colspan="2">template&lt;class T &gt; </td></tr>
<tr class="memitem:ad93d654b978add6b2f0dfb9f91490209"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#ad93d654b978add6b2f0dfb9f91490209">set</a> (const std::vector&lt; <a class="el" href="classcytnx_1_1Accessor.html">cytnx::Accessor</a> &gt; &amp;accessors, const T &amp;rc)</td></tr>
<tr class="memdesc:ad93d654b978add6b2f0dfb9f91490209"><td class="mdescLeft">&#160;</td><td class="mdescRight">set elements with the input constant using <a class="el" href="classcytnx_1_1Accessor.html" title="object that mimic the python slice to access elements in C++ [this is for c++ API only]...">Accessor</a> (C++ API) / slices (python API)  <a href="#ad93d654b978add6b2f0dfb9f91490209">More...</a><br /></td></tr>
<tr class="separator:ad93d654b978add6b2f0dfb9f91490209"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fd5918a0f64ebd74fe34cb8b8164c30"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Storage.html">Storage</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a0fd5918a0f64ebd74fe34cb8b8164c30">storage</a> () const</td></tr>
<tr class="memdesc:a0fd5918a0f64ebd74fe34cb8b8164c30"><td class="mdescLeft">&#160;</td><td class="mdescRight">return the storage of current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.  <a href="#a0fd5918a0f64ebd74fe34cb8b8164c30">More...</a><br /></td></tr>
<tr class="separator:a0fd5918a0f64ebd74fe34cb8b8164c30"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c7f2bac2a03be7d22769c7cb896afbe"><td class="memTemplParams" colspan="2">template&lt;class T &gt; </td></tr>
<tr class="memitem:a0c7f2bac2a03be7d22769c7cb896afbe"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#a0c7f2bac2a03be7d22769c7cb896afbe">fill</a> (const T &amp;val)</td></tr>
<tr class="memdesc:a0c7f2bac2a03be7d22769c7cb896afbe"><td class="mdescLeft">&#160;</td><td class="mdescRight">fill all the element of current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> with the value.  <a href="#a0c7f2bac2a03be7d22769c7cb896afbe">More...</a><br /></td></tr>
<tr class="separator:a0c7f2bac2a03be7d22769c7cb896afbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeae314f040e27b581d73c82b33ab6a59"><td class="memItemLeft" align="right" valign="top"><a id="aeae314f040e27b581d73c82b33ab6a59"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>equiv</b> (const <a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;rhs)</td></tr>
<tr class="separator:aeae314f040e27b581d73c82b33ab6a59"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14586eb5096b7c98465dc6081042922b"><td class="memTemplParams" colspan="2"><a id="a14586eb5096b7c98465dc6081042922b"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a14586eb5096b7c98465dc6081042922b"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>operator+=</b> (const T &amp;rc)</td></tr>
<tr class="separator:a14586eb5096b7c98465dc6081042922b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab78b7d778d79c005ca5cc24385391075"><td class="memTemplParams" colspan="2"><a id="ab78b7d778d79c005ca5cc24385391075"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:ab78b7d778d79c005ca5cc24385391075"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>operator-=</b> (const T &amp;rc)</td></tr>
<tr class="separator:ab78b7d778d79c005ca5cc24385391075"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ab679c8ccf4a9b8df95c3a622b98c2c"><td class="memTemplParams" colspan="2"><a id="a9ab679c8ccf4a9b8df95c3a622b98c2c"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a9ab679c8ccf4a9b8df95c3a622b98c2c"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>operator*=</b> (const T &amp;rc)</td></tr>
<tr class="separator:a9ab679c8ccf4a9b8df95c3a622b98c2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ba77e4d476866efbc330d48f1e6fbef"><td class="memTemplParams" colspan="2"><a id="a7ba77e4d476866efbc330d48f1e6fbef"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a7ba77e4d476866efbc330d48f1e6fbef"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>operator/=</b> (const T &amp;rc)</td></tr>
<tr class="separator:a7ba77e4d476866efbc330d48f1e6fbef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafd7446e798d34427d4e6a9571861111"><td class="memTemplParams" colspan="2"><a id="aafd7446e798d34427d4e6a9571861111"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:aafd7446e798d34427d4e6a9571861111"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Add</b> (const T &amp;rhs)</td></tr>
<tr class="separator:aafd7446e798d34427d4e6a9571861111"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7ab4b9ee38f619a60c26f203539db65"><td class="memTemplParams" colspan="2"><a id="ac7ab4b9ee38f619a60c26f203539db65"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:ac7ab4b9ee38f619a60c26f203539db65"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Add_</b> (const T &amp;rhs)</td></tr>
<tr class="separator:ac7ab4b9ee38f619a60c26f203539db65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4648eef7874bad42d6d7b15fb1598644"><td class="memTemplParams" colspan="2"><a id="a4648eef7874bad42d6d7b15fb1598644"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a4648eef7874bad42d6d7b15fb1598644"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Sub</b> (const T &amp;rhs)</td></tr>
<tr class="separator:a4648eef7874bad42d6d7b15fb1598644"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3482ddb0ebd4ae6585dcea7c96702e0c"><td class="memTemplParams" colspan="2"><a id="a3482ddb0ebd4ae6585dcea7c96702e0c"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a3482ddb0ebd4ae6585dcea7c96702e0c"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Sub_</b> (const T &amp;rhs)</td></tr>
<tr class="separator:a3482ddb0ebd4ae6585dcea7c96702e0c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a443885c8f02ab5352d81255e4650cf32"><td class="memTemplParams" colspan="2"><a id="a443885c8f02ab5352d81255e4650cf32"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a443885c8f02ab5352d81255e4650cf32"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Mul</b> (const T &amp;rhs)</td></tr>
<tr class="separator:a443885c8f02ab5352d81255e4650cf32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92461c94266f7185da6f8fd35d1ffee4"><td class="memTemplParams" colspan="2"><a id="a92461c94266f7185da6f8fd35d1ffee4"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a92461c94266f7185da6f8fd35d1ffee4"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Mul_</b> (const T &amp;rhs)</td></tr>
<tr class="separator:a92461c94266f7185da6f8fd35d1ffee4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add04fc004ccab102743f3e392f6bb482"><td class="memTemplParams" colspan="2"><a id="add04fc004ccab102743f3e392f6bb482"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:add04fc004ccab102743f3e392f6bb482"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Div</b> (const T &amp;rhs)</td></tr>
<tr class="separator:add04fc004ccab102743f3e392f6bb482"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a030748d3e2003f655b1cf73fe0d55a63"><td class="memTemplParams" colspan="2"><a id="a030748d3e2003f655b1cf73fe0d55a63"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:a030748d3e2003f655b1cf73fe0d55a63"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Div_</b> (const T &amp;rhs)</td></tr>
<tr class="separator:a030748d3e2003f655b1cf73fe0d55a63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeee6153da17147b82857e342e2a35c52"><td class="memTemplParams" colspan="2"><a id="aeee6153da17147b82857e342e2a35c52"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:aeee6153da17147b82857e342e2a35c52"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Cpr</b> (const T &amp;rhs)</td></tr>
<tr class="separator:aeee6153da17147b82857e342e2a35c52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9e9ea98664899db1ce86b88e136595e"><td class="memTemplParams" colspan="2"><a id="ae9e9ea98664899db1ce86b88e136595e"></a>
template&lt;class T &gt; </td></tr>
<tr class="memitem:ae9e9ea98664899db1ce86b88e136595e"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memTemplItemRight" valign="bottom"><b>Cpr_</b> (const T &amp;rhs)</td></tr>
<tr class="separator:ae9e9ea98664899db1ce86b88e136595e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0dc4a19c04d3576c3364deb74251d855"><td class="memItemLeft" align="right" valign="top"><a id="a0dc4a19c04d3576c3364deb74251d855"></a>
std::vector&lt; <a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>Svd</b> (const bool &amp;is_U=true, const bool &amp;is_vT=true)</td></tr>
<tr class="separator:a0dc4a19c04d3576c3364deb74251d855"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac456006e0fbd6108dddc520e4ad12ff7"><td class="memItemLeft" align="right" valign="top"><a id="ac456006e0fbd6108dddc520e4ad12ff7"></a>
std::vector&lt; <a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>Eigh</b> (const bool &amp;is_V=false)</td></tr>
<tr class="separator:ac456006e0fbd6108dddc520e4ad12ff7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad21dcb7ba06d23c78ee5fd4e9266a462"><td class="memItemLeft" align="right" valign="top"><a id="ad21dcb7ba06d23c78ee5fd4e9266a462"></a>
<a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>Inv_</b> ()</td></tr>
<tr class="separator:ad21dcb7ba06d23c78ee5fd4e9266a462"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ed6193e29219ff1a2ca2ca95b8b5969"><td class="memItemLeft" align="right" valign="top"><a id="a7ed6193e29219ff1a2ca2ca95b8b5969"></a>
<a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Inv</b> ()</td></tr>
<tr class="separator:a7ed6193e29219ff1a2ca2ca95b8b5969"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9312d8faf3fdc8ffe5a7687f88986a1e"><td class="memItemLeft" align="right" valign="top"><a id="a9312d8faf3fdc8ffe5a7687f88986a1e"></a>
<a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>Conj_</b> ()</td></tr>
<tr class="separator:a9312d8faf3fdc8ffe5a7687f88986a1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf65f5c4d143eb165f7161e58a06b7e4"><td class="memItemLeft" align="right" valign="top"><a id="acf65f5c4d143eb165f7161e58a06b7e4"></a>
<a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Conj</b> ()</td></tr>
<tr class="separator:acf65f5c4d143eb165f7161e58a06b7e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ebfd2713960db958ddb23c4e06c17c4"><td class="memItemLeft" align="right" valign="top"><a id="a4ebfd2713960db958ddb23c4e06c17c4"></a>
<a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>Exp_</b> ()</td></tr>
<tr class="separator:a4ebfd2713960db958ddb23c4e06c17c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca1b7e9ae53b3529a7f79b24991c9373"><td class="memItemLeft" align="right" valign="top"><a id="aca1b7e9ae53b3529a7f79b24991c9373"></a>
<a class="el" href="classcytnx_1_1Tensor.html">Tensor</a>&#160;</td><td class="memItemRight" valign="bottom"><b>Exp</b> ()</td></tr>
<tr class="separator:aca1b7e9ae53b3529a7f79b24991c9373"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr><td colspan="2"><div class="groupHeader"></div></td></tr>
<tr class="memitem:afdb4470e0dc934964d80aa9c761cca48"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#afdb4470e0dc934964d80aa9c761cca48">Init</a> (const std::vector&lt; cytnx_uint64 &gt; &amp;<a class="el" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>, const unsigned int &amp;<a class="el" href="classcytnx_1_1Tensor.html#a4472af6f8e825a13440e832bf82fb627">dtype</a>=Type.Double, const int &amp;<a class="el" href="classcytnx_1_1Tensor.html#ac6d3310eb4defbdacf662dcd81d8fe09">device</a>=-1)</td></tr>
<tr class="memdesc:afdb4470e0dc934964d80aa9c761cca48"><td class="mdescLeft">&#160;</td><td class="mdescRight">initialize a <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>  <a href="#afdb4470e0dc934964d80aa9c761cca48">More...</a><br /></td></tr>
<tr class="separator:afdb4470e0dc934964d80aa9c761cca48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afdcff16b2096d10b524161be52ba767e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcytnx_1_1Tensor.html#afdcff16b2096d10b524161be52ba767e">Tensor</a> (const std::vector&lt; cytnx_uint64 &gt; &amp;<a class="el" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>, const unsigned int &amp;<a class="el" href="classcytnx_1_1Tensor.html#a4472af6f8e825a13440e832bf82fb627">dtype</a>=Type.Double, const int &amp;<a class="el" href="classcytnx_1_1Tensor.html#ac6d3310eb4defbdacf662dcd81d8fe09">device</a>=-1)</td></tr>
<tr class="memdesc:afdcff16b2096d10b524161be52ba767e"><td class="mdescLeft">&#160;</td><td class="mdescRight">initialize a <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>  <a href="#afdcff16b2096d10b524161be52ba767e">More...</a><br /></td></tr>
<tr class="separator:afdcff16b2096d10b524161be52ba767e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>an tensor (multi-dimensional array) </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="afdcff16b2096d10b524161be52ba767e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afdcff16b2096d10b524161be52ba767e">&#9670;&nbsp;</a></span>Tensor()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">cytnx::Tensor::Tensor </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; cytnx_uint64 &gt; &amp;&#160;</td>
          <td class="paramname"><em>shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned int &amp;&#160;</td>
          <td class="paramname"><em>dtype</em> = <code>Type.Double</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>device</em> = <code>-1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>initialize a <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>the shape of tensor. </td></tr>
    <tr><td class="paramname">dtype</td><td>the dtype of tensor. This can be any of type defined in cytnx::Type </td></tr>
    <tr><td class="paramname">device</td><td>the device that tensor to be created. This can be cytnx::Device.cpu or cytnx::Device.cuda+&lt;gpuid&gt;</td></tr>
  </table>
  </dd>
</dl>
<p>[Note]</p><ol type="1">
<li>the content of <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> created will be un-initialize! See <a class="el" href="namespacecytnx.html#ab8a79a03fb0465f3eb2641017f3f1755">zeros()</a>, <a class="el" href="namespacecytnx.html#a83fb7bbe73368751a0d0f535d4a10a33">ones() </a> or <a class="el" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange() </a> for generating an <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.</li>
</ol>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <span class="comment">/*</span></div><div class="line"><span class="comment">        1. Create a Tensor with </span></div><div class="line"><span class="comment">        shape (3,4,5),</span></div><div class="line"><span class="comment">        dtype =Type.Double [default],</span></div><div class="line"><span class="comment">        device=Device.cpu [default]</span></div><div class="line"><span class="comment">    */</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A({3,4,5});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">/*</span></div><div class="line"><span class="comment">        2. Create a Tensor with </span></div><div class="line"><span class="comment">        shape (3,4,5),</span></div><div class="line"><span class="comment">        dtype =Type.Uint64,</span></div><div class="line"><span class="comment">        device=Device.cpu [default],</span></div><div class="line"><span class="comment">        [Note] the dtype can be any one of the supported type.</span></div><div class="line"><span class="comment">    */</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B({3,4,5},Type.Uint64);</div><div class="line">    cout &lt;&lt; B &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">/*</span></div><div class="line"><span class="comment">        3. Initialize a Tensor with </span></div><div class="line"><span class="comment">        shape (3,4,5),</span></div><div class="line"><span class="comment">        dtype =Type.Double,</span></div><div class="line"><span class="comment">        device=Device.cuda+0, (on gpu with gpu-id=0)</span></div><div class="line"><span class="comment">        [Note] the gpu device can be set with Device.cuda+&lt;gpu-id&gt;</span></div><div class="line"><span class="comment">    */</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> C({3,4,5},Type.Double,Device.cuda+0);</div><div class="line">    cout &lt;&lt; C &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">//4. Create an empty Tensor, and init later</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> D;</div><div class="line">    D.<a class="code" href="classcytnx_1_1Tensor.html#afdb4470e0dc934964d80aa9c761cca48">Init</a>({3,4,5},Type.Double,Device.cpu);</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]]



Total elem: 60
type  : Uint64
cytnx device: CPU
Shape : (3,4,5)
[[[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]
 [[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]
 [[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CUDA/GPU-id:0
Shape : (3,4,5)
[[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]]


</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#1. Create a Tensor with </span></div><div class="line"><span class="comment">#  shape (3,4,5),</span></div><div class="line"><span class="comment">#  dtype =Type.Double [default],</span></div><div class="line"><span class="comment">#  device=Device.cpu [default]</span></div><div class="line">A = Tensor([3,4,5])</div><div class="line">print(A)</div><div class="line"></div><div class="line"><span class="comment">#2. Create a Tensor with </span></div><div class="line"><span class="comment">#  shape (3,4,5),</span></div><div class="line"><span class="comment">#  dtype =Type.Uint64,</span></div><div class="line"><span class="comment">#  device=Device.cpu [default],</span></div><div class="line"><span class="comment">#  [Note] the dtype can be any one of the supported type.</span></div><div class="line">B = Tensor([3,4,5],dtype=Type.Uint64)</div><div class="line">print(B)</div><div class="line"></div><div class="line"><span class="comment">#3. Initialize a Tensor with </span></div><div class="line"><span class="comment">#  shape (3,4,5),</span></div><div class="line"><span class="comment">#  dtype =Type.Double,</span></div><div class="line"><span class="comment">#  device=Device.cuda+0, (on gpu with gpu-id=0)</span></div><div class="line"><span class="comment">#  [Note] the gpu device can be set with Device.cuda+&lt;gpu-id&gt;</span></div><div class="line">C = Tensor([3,4,5],dtype=Type.Double,device=Device.cuda+0);</div><div class="line">print(C)</div><div class="line"></div><div class="line"><span class="comment">#4. Create an empty Tensor, and init later</span></div><div class="line">D = Tensor()</div><div class="line">D.Init([3,4,5],dtype=Type.Double,device=Device.cpu);</div><div class="line"></div><div class="line"></div><div class="line"> </div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[4.64000e-310 1.06098e-153 8.19691e+247 5.39115e+228 1.23762e+224 ]
  [2.66064e-260 7.27456e+199 2.41318e+185 7.86015e-85 3.06263e+223 ]
  [4.90606e-109 3.94655e+180 3.75209e+199 4.96845e+180 1.18414e+224 ]
  [7.86015e-85 7.36507e+228 2.07049e-28 5.74971e+169 6.16785e+223 ]]
 [[2.04724e+190 9.49253e-154 1.39388e-258 7.33721e+223 1.44421e+214 ]
  [1.28714e+272 2.13269e+102 1.67772e+243 3.91625e-27 5.36154e+276 ]
  [1.18414e+224 5.50421e-95 2.38345e+180 8.89470e+252 2.17235e-153 ]
  [2.50022e+243 6.96742e+252 1.99999e+174 7.26588e+223 1.99999e+174 ]]
 [[2.42614e+198 8.04138e-96 9.69724e+189 2.91741e-14 9.47071e-154 ]
  [1.39388e-258 6.16785e+223 1.12648e-153 7.29537e+175 1.44421e+214 ]
  [1.28714e+272 3.25422e+97 7.10583e+159 5.38206e+228 3.06500e+169 ]
  [1.16331e+253 7.36507e+228 2.54716e+151 2.49867e+262 2.68247e-260 ]]]



Total elem: 60
type  : Uint64
cytnx device: CPU
Shape : (3,4,5)
[[[                  0           539784039          1936159329          1869378149          1853187616 ]
  [          168439406           678194281          2036539450          1853127011          1919906670 ]
  [         1663056492           539588709           174419567          1819044198          1663056486 ]
  [         1954112302          1869835877           540699745           695756140          1701736270 ]]
 [[         1818846752           540698220          2036543096          1936614740           980181366 ]
  [          539587681           174419567          1819044198          1663056486          1954112302 ]
  [         1869835877           540699745           757082484           168453486           678194281 ]
  [         2036539450          1853127011          1919906670          1763719788          1310735917 ]]
 [[          539899402          1818587944          2020504697          1412331630          1981820018 ]
  [          695496297          1701736270          1818846752           540698220          2036543096 ]
  [         1936614740           980181366          1043144745           940182117          1932029036 ]
  [         1954112288          2020504697           745697139          1852383290          1867391038 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CUDA/GPU-id:0
Shape : (3,4,5)
[[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]]





</pre> 
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a7b996d3281e7375b29a7cfe4273b299f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b996d3281e7375b29a7cfe4273b299f">&#9670;&nbsp;</a></span>astype()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> cytnx::Tensor::astype </td>
          <td>(</td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>new_type</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>return a new <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> that cast to different dtype. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_type</td><td>the new dtype. It can be any type defined in cytnx::Type </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>[<a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>]</dd></dl>
<h2>Note:</h2>
<p>If the new_type is the same as dtype of the current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>, return self.</p>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#ab8a79a03fb0465f3eb2641017f3f1755">zeros</a>({3,4,5},Type.Double);</div><div class="line">    cout &lt;&lt; A;</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = A.<a class="code" href="classcytnx_1_1Storage.html#a8310d8dbb70510272ded2e3d01be25f0">astype</a>(Type.Uint64);</div><div class="line">    cout &lt;&lt; B;</div><div class="line"></div><div class="line">    <span class="comment">// the new type is the same as current dtype, return self.</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> C = A.<a class="code" href="classcytnx_1_1Storage.html#a8310d8dbb70510272ded2e3d01be25f0">astype</a>(Type.Double);</div><div class="line">    cout &lt;&lt; is(C,A) &lt;&lt; endl; <span class="comment">// this should be true.</span></div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]]


Total elem: 60
type  : Uint64
cytnx device: CPU
Shape : (3,4,5)
[[[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]
 [[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]
 [[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]]

1
</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = zeros([3,4,5],dtype=Type.Double)</div><div class="line">print(A)</div><div class="line"></div><div class="line">B = A.astype(Type.Uint64)</div><div class="line">print(B)</div><div class="line"></div><div class="line">C = A.astype(Type.Double)</div><div class="line">print(C <span class="keywordflow">is</span> A)</div><div class="line"></div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]]



Total elem: 60
type  : Uint64
cytnx device: CPU
Shape : (3,4,5)
[[[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]
 [[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]
 [[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]]




True
</pre> 
</div>
</div>
<a id="a697b114d1df390ca558ea9211c2d683b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a697b114d1df390ca558ea9211c2d683b">&#9670;&nbsp;</a></span>at()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">T&amp; cytnx::Tensor::at </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; cytnx_uint64 &gt; &amp;&#160;</td>
          <td class="paramname"><em>locator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>[C++ only] get an element at specific location. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">locator</td><td>the location of the element </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>[ref]</dd></dl>
<h2>Note:</h2>
<ol type="1">
<li>This is for C++ API only!</li>
<li>need template instantiation to resolve the type, which should be consist with the dtype of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>. An error will be issued if the template type is inconsist with the current dtype of <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.</li>
<li>For python API, use [] directly to get element.</li>
</ol>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange</a>(30,Type.Float).<a class="code" href="classcytnx_1_1Tensor.html#a182f8f7b3ae3d0db8ed55d2adf8c6b45">reshape</a>({2,3,5});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">// note that type resolver should be consist with the dtype </span></div><div class="line">    cout &lt;&lt; A.<a class="code" href="classcytnx_1_1Tensor.html#a697b114d1df390ca558ea9211c2d683b">at</a>&lt;cytnx_float&gt;({0,0,2}) &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">// the return is a ref., can be modify directly.</span></div><div class="line">    A.<a class="code" href="classcytnx_1_1Tensor.html#a697b114d1df390ca558ea9211c2d683b">at</a>&lt;cytnx_float&gt;({0,0,2}) = 999;</div><div class="line">    </div><div class="line">    cout &lt;&lt; A.<a class="code" href="classcytnx_1_1Tensor.html#a697b114d1df390ca558ea9211c2d683b">at</a>&lt;cytnx_float&gt;({0,0,2}) &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 30
type  : Float32
cytnx device: CPU
Shape : (2,3,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]]
 [[1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]
  [2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]]]


2
999
</pre> 
</div>
</div>
<a id="a5e2248e9babdb786167ed349df9084ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e2248e9babdb786167ed349df9084ae">&#9670;&nbsp;</a></span>clone()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> cytnx::Tensor::clone </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>return a clone of the current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>[<a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>]</dd></dl>
<p>description:<br />
 In C++ API, the behavior of assignment operator is designed to have same behavior as python,<br />
 to have a copy of the current tensor, we call clone to return a copy.</p>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A({3,4,5});</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = A; <span class="comment">// B shares same object with A</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> C = A.<a class="code" href="classcytnx_1_1Tensor.html#a5e2248e9babdb786167ed349df9084ae">clone</a>(); <span class="comment">// C is a copy of A</span></div><div class="line">    </div><div class="line">    <span class="comment">// use is() to check if two variable shares same object</span></div><div class="line">    cout &lt;&lt; is(B,A) &lt;&lt; endl;</div><div class="line">    cout &lt;&lt; is(C,A) &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">1
0
</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = Tensor([3,4,5])</div><div class="line"></div><div class="line">B = A</div><div class="line">C = A.clone()</div><div class="line"></div><div class="line">print(B <span class="keywordflow">is</span> A)</div><div class="line">print(C <span class="keywordflow">is</span> A)</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">True
False
</pre> 
</div>
</div>
<a id="a127e50508e1ee0eadf11601d66d76988"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a127e50508e1ee0eadf11601d66d76988">&#9670;&nbsp;</a></span>contiguous()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> cytnx::Tensor::contiguous </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Make the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> contiguous by coalescing the memory (storage). </p>
<dl class="section return"><dt>Returns</dt><dd>[<a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>] a new <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> that is with contiguous memory (storage).</dd></dl>
<p>See also <a class="el" href="classcytnx_1_1Tensor.html#a405470654ef4ef5fc0b1d24754a3daf9">Tensor::contiguous_() </a></p>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A({3,4,5});</div><div class="line">    cout &lt;&lt; A.<a class="code" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>() &lt;&lt; endl;</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = A.<a class="code" href="classcytnx_1_1Tensor.html#adbdc402a8c4d6d738523a888bcf9c0c2">permute</a>({0,2,1});</div><div class="line">    cout &lt;&lt; B.<a class="code" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>() &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">//[Note] permute will not actually move the internal memory (storage) layout.</span></div><div class="line">    <span class="comment">//       this is called non-contiguous status. </span></div><div class="line">    <span class="comment">//       the memory layout will only move when Tensor.contiguous() is called.</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> C = B.<a class="code" href="classcytnx_1_1Tensor.html#a127e50508e1ee0eadf11601d66d76988">contiguous</a>(); <span class="comment">//actual moving the memory</span></div><div class="line">    cout &lt;&lt; B.is_contiguous() &lt;&lt; endl; <span class="comment">// false.</span></div><div class="line">    cout &lt;&lt; C.is_contiguous() &lt;&lt; endl; <span class="comment">// true.</span></div><div class="line">    cout &lt;&lt; C.<a class="code" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>() &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">Vector Print:
Total Elements:3
[3, 4, 5]

Vector Print:
Total Elements:3
[3, 5, 4]

0
1
Vector Print:
Total Elements:3
[3, 5, 4]

</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = Tensor([3,4,5])</div><div class="line">print(A.shape())</div><div class="line"></div><div class="line">B = A.permute(0,2,1)</div><div class="line">print(B.shape())</div><div class="line"></div><div class="line">C = B.contiguous()</div><div class="line">print(B.is_contiguous()) <span class="comment">#false</span></div><div class="line">print(C.is_contiguous()) <span class="comment">#true</span></div><div class="line">print(C.shape())</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">[3, 4, 5]
[3, 5, 4]
False
True
[3, 5, 4]
</pre> 
</div>
</div>
<a id="a405470654ef4ef5fc0b1d24754a3daf9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a405470654ef4ef5fc0b1d24754a3daf9">&#9670;&nbsp;</a></span>contiguous_()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cytnx::Tensor::contiguous_ </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Make the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> contiguous by coalescing the memory (storage), inplacely. </p>
<p>See also <a class="el" href="classcytnx_1_1Tensor.html#a127e50508e1ee0eadf11601d66d76988">Tensor::contiguous() </a></p>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A({3,4,5});</div><div class="line">    cout &lt;&lt; A.<a class="code" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>() &lt;&lt; endl;</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = A.<a class="code" href="classcytnx_1_1Tensor.html#adbdc402a8c4d6d738523a888bcf9c0c2">permute</a>({0,2,1});</div><div class="line">    cout &lt;&lt; B.<a class="code" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>() &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">//[Note] permute will not actually move the internal memory (storage) layout.</span></div><div class="line">    <span class="comment">//       this is called non-contiguous status. </span></div><div class="line">    <span class="comment">//       the memory layout will only move when Tensor.contiguous() is called.</span></div><div class="line">    cout &lt;&lt; B.is_contiguous() &lt;&lt; endl; <span class="comment">// false.</span></div><div class="line">    B.<a class="code" href="classcytnx_1_1Tensor.html#a405470654ef4ef5fc0b1d24754a3daf9">contiguous_</a>(); <span class="comment">//actual moving the memory</span></div><div class="line">    cout &lt;&lt; B.is_contiguous() &lt;&lt; endl; <span class="comment">// true.</span></div><div class="line">    </div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">Vector Print:
Total Elements:3
[3, 4, 5]

Vector Print:
Total Elements:3
[3, 5, 4]

0
1
</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = Tensor([3,4,5])</div><div class="line">print(A.shape())</div><div class="line"></div><div class="line">B = A.permute(0,2,1)</div><div class="line">print(B.shape())</div><div class="line"></div><div class="line">print(B.is_contiguous()) <span class="comment">#false</span></div><div class="line">B.contiguous_()</div><div class="line">print(B.is_contiguous()) <span class="comment">#true</span></div><div class="line">    </div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">[3, 4, 5]
[3, 5, 4]
False
True
</pre> 
</div>
</div>
<a id="ac6d3310eb4defbdacf662dcd81d8fe09"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac6d3310eb4defbdacf662dcd81d8fe09">&#9670;&nbsp;</a></span>device()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int cytnx::Tensor::device </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>the device-id of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </p>
<dl class="section return"><dt>Returns</dt><dd>[cytnx_int64] the device_id of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </dd></dl>

</div>
</div>
<a id="a335f7625fa01784f49b2223238d0c14e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a335f7625fa01784f49b2223238d0c14e">&#9670;&nbsp;</a></span>device_str()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string cytnx::Tensor::device_str </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>the device (in string) of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </p>
<dl class="section return"><dt>Returns</dt><dd>[std::string] the device of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </dd></dl>

</div>
</div>
<a id="a4472af6f8e825a13440e832bf82fb627"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4472af6f8e825a13440e832bf82fb627">&#9670;&nbsp;</a></span>dtype()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int cytnx::Tensor::dtype </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>the dtype-id of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </p>
<dl class="section return"><dt>Returns</dt><dd>[cytnx_uint64] the dtype_id of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </dd></dl>

</div>
</div>
<a id="a9e09106c7529e8be90caa52e1541e498"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e09106c7529e8be90caa52e1541e498">&#9670;&nbsp;</a></span>dtype_str()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string cytnx::Tensor::dtype_str </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>the dtype (in string) of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </p>
<dl class="section return"><dt>Returns</dt><dd>[std::string] the dtype of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </dd></dl>

</div>
</div>
<a id="a0c7f2bac2a03be7d22769c7cb896afbe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c7f2bac2a03be7d22769c7cb896afbe">&#9670;&nbsp;</a></span>fill()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cytnx::Tensor::fill </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>val</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>fill all the element of current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> with the value. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">val</td><td>the assigned value</td></tr>
  </table>
  </dd>
</dl>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){</div><div class="line"></div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange</a>(60).<a class="code" href="classcytnx_1_1Tensor.html#a182f8f7b3ae3d0db8ed55d2adf8c6b45">reshape</a>({3,4,5});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    A.<a class="code" href="classcytnx_1_1Tensor.html#a0c7f2bac2a03be7d22769c7cb896afbe">fill</a>(999);</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 ]
  [4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 ]
  [5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 ]
  [5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]]
 [[9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]]
 [[9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]]]


</pre> <h3>python API</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = arange(60).reshape(3,4,5)</div><div class="line">print(A)</div><div class="line"></div><div class="line">A.fill(999)</div><div class="line">print(A)</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 ]
  [4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 ]
  [5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 ]
  [5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]]
 [[9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]]
 [[9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]
  [9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 9.99000e+02 ]]]




</pre> 
</div>
</div>
<a id="ad7b928e4cb89d40cbd99aefab9aa0075"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad7b928e4cb89d40cbd99aefab9aa0075">&#9670;&nbsp;</a></span>get()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> cytnx::Tensor::get </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="classcytnx_1_1Accessor.html">cytnx::Accessor</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>accessors</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>get elements using <a class="el" href="classcytnx_1_1Accessor.html" title="object that mimic the python slice to access elements in C++ [this is for c++ API only]...">Accessor</a> (C++ API) / slices (python API) </p>
<dl class="section return"><dt>Returns</dt><dd>[<a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>]</dd></dl>
<p>See also <a class="el" href="classcytnx_1_1Accessor.html">Accessor</a> for cordinate with <a class="el" href="classcytnx_1_1Accessor.html" title="object that mimic the python slice to access elements in C++ [this is for c++ API only]...">Accessor</a> in C++ API.</p>
<h2>Note:</h2>
<ol type="1">
<li>the return will be a new <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> instance, which not share memory with the current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.</li>
</ol>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){</div><div class="line"></div><div class="line">    <span class="keyword">typedef</span> <a class="code" href="classcytnx_1_1Accessor.html">Accessor</a> ac;</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange</a>(60).<a class="code" href="classcytnx_1_1Tensor.html#a182f8f7b3ae3d0db8ed55d2adf8c6b45">reshape</a>({3,4,5});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = A.<a class="code" href="classcytnx_1_1Tensor.html#ad7b928e4cb89d40cbd99aefab9aa0075">get</a>({ac(2),ac::all(),ac::range(2,5,1)});</div><div class="line">    cout &lt;&lt; B &lt;&lt; endl;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 ]
  [4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 ]
  [5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 ]
  [5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]]



Total elem: 12
type  : Double (Float64)
cytnx device: CPU
Shape : (4,3)
[[4.20000e+01 4.30000e+01 4.40000e+01 ]
 [4.70000e+01 4.80000e+01 4.90000e+01 ]
 [5.20000e+01 5.30000e+01 5.40000e+01 ]
 [5.70000e+01 5.80000e+01 5.90000e+01 ]]


</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = arange(60).reshape(3,4,5)</div><div class="line">print(A)</div><div class="line"></div><div class="line">B = A[2,:,2:5:1]</div><div class="line">print(B)</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 ]
  [4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 ]
  [5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 ]
  [5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]]



Total elem: 12
type  : Double (Float64)
cytnx device: CPU
Shape : (4,3)
[[4.20000e+01 4.30000e+01 4.40000e+01 ]
 [4.70000e+01 4.80000e+01 4.90000e+01 ]
 [5.20000e+01 5.30000e+01 5.40000e+01 ]
 [5.70000e+01 5.80000e+01 5.90000e+01 ]]




</pre> 
</div>
</div>
<a id="afdb4470e0dc934964d80aa9c761cca48"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afdb4470e0dc934964d80aa9c761cca48">&#9670;&nbsp;</a></span>Init()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cytnx::Tensor::Init </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; cytnx_uint64 &gt; &amp;&#160;</td>
          <td class="paramname"><em>shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned int &amp;&#160;</td>
          <td class="paramname"><em>dtype</em> = <code>Type.Double</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>device</em> = <code>-1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>initialize a <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>the shape of tensor. </td></tr>
    <tr><td class="paramname">dtype</td><td>the dtype of tensor. This can be any of type defined in cytnx::Type </td></tr>
    <tr><td class="paramname">device</td><td>the device that tensor to be created. This can be cytnx::Device.cpu or cytnx::Device.cuda+&lt;gpuid&gt;</td></tr>
  </table>
  </dd>
</dl>
<p>[Note]</p><ol type="1">
<li>the content of <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> created will be un-initialize! See <a class="el" href="namespacecytnx.html#ab8a79a03fb0465f3eb2641017f3f1755">zeros()</a>, <a class="el" href="namespacecytnx.html#a83fb7bbe73368751a0d0f535d4a10a33">ones() </a> or <a class="el" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange() </a> for generating an <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.</li>
</ol>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <span class="comment">/*</span></div><div class="line"><span class="comment">        1. Create a Tensor with </span></div><div class="line"><span class="comment">        shape (3,4,5),</span></div><div class="line"><span class="comment">        dtype =Type.Double [default],</span></div><div class="line"><span class="comment">        device=Device.cpu [default]</span></div><div class="line"><span class="comment">    */</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A({3,4,5});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">/*</span></div><div class="line"><span class="comment">        2. Create a Tensor with </span></div><div class="line"><span class="comment">        shape (3,4,5),</span></div><div class="line"><span class="comment">        dtype =Type.Uint64,</span></div><div class="line"><span class="comment">        device=Device.cpu [default],</span></div><div class="line"><span class="comment">        [Note] the dtype can be any one of the supported type.</span></div><div class="line"><span class="comment">    */</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B({3,4,5},Type.Uint64);</div><div class="line">    cout &lt;&lt; B &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">/*</span></div><div class="line"><span class="comment">        3. Initialize a Tensor with </span></div><div class="line"><span class="comment">        shape (3,4,5),</span></div><div class="line"><span class="comment">        dtype =Type.Double,</span></div><div class="line"><span class="comment">        device=Device.cuda+0, (on gpu with gpu-id=0)</span></div><div class="line"><span class="comment">        [Note] the gpu device can be set with Device.cuda+&lt;gpu-id&gt;</span></div><div class="line"><span class="comment">    */</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> C({3,4,5},Type.Double,Device.cuda+0);</div><div class="line">    cout &lt;&lt; C &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">//4. Create an empty Tensor, and init later</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> D;</div><div class="line">    D.<a class="code" href="classcytnx_1_1Tensor.html#afdb4470e0dc934964d80aa9c761cca48">Init</a>({3,4,5},Type.Double,Device.cpu);</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]]



Total elem: 60
type  : Uint64
cytnx device: CPU
Shape : (3,4,5)
[[[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]
 [[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]
 [[                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]
  [                  0                   0                   0                   0                   0 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CUDA/GPU-id:0
Shape : (3,4,5)
[[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]]


</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#1. Create a Tensor with </span></div><div class="line"><span class="comment">#  shape (3,4,5),</span></div><div class="line"><span class="comment">#  dtype =Type.Double [default],</span></div><div class="line"><span class="comment">#  device=Device.cpu [default]</span></div><div class="line">A = Tensor([3,4,5])</div><div class="line">print(A)</div><div class="line"></div><div class="line"><span class="comment">#2. Create a Tensor with </span></div><div class="line"><span class="comment">#  shape (3,4,5),</span></div><div class="line"><span class="comment">#  dtype =Type.Uint64,</span></div><div class="line"><span class="comment">#  device=Device.cpu [default],</span></div><div class="line"><span class="comment">#  [Note] the dtype can be any one of the supported type.</span></div><div class="line">B = Tensor([3,4,5],dtype=Type.Uint64)</div><div class="line">print(B)</div><div class="line"></div><div class="line"><span class="comment">#3. Initialize a Tensor with </span></div><div class="line"><span class="comment">#  shape (3,4,5),</span></div><div class="line"><span class="comment">#  dtype =Type.Double,</span></div><div class="line"><span class="comment">#  device=Device.cuda+0, (on gpu with gpu-id=0)</span></div><div class="line"><span class="comment">#  [Note] the gpu device can be set with Device.cuda+&lt;gpu-id&gt;</span></div><div class="line">C = Tensor([3,4,5],dtype=Type.Double,device=Device.cuda+0);</div><div class="line">print(C)</div><div class="line"></div><div class="line"><span class="comment">#4. Create an empty Tensor, and init later</span></div><div class="line">D = Tensor()</div><div class="line">D.Init([3,4,5],dtype=Type.Double,device=Device.cpu);</div><div class="line"></div><div class="line"></div><div class="line"> </div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[4.64000e-310 1.06098e-153 8.19691e+247 5.39115e+228 1.23762e+224 ]
  [2.66064e-260 7.27456e+199 2.41318e+185 7.86015e-85 3.06263e+223 ]
  [4.90606e-109 3.94655e+180 3.75209e+199 4.96845e+180 1.18414e+224 ]
  [7.86015e-85 7.36507e+228 2.07049e-28 5.74971e+169 6.16785e+223 ]]
 [[2.04724e+190 9.49253e-154 1.39388e-258 7.33721e+223 1.44421e+214 ]
  [1.28714e+272 2.13269e+102 1.67772e+243 3.91625e-27 5.36154e+276 ]
  [1.18414e+224 5.50421e-95 2.38345e+180 8.89470e+252 2.17235e-153 ]
  [2.50022e+243 6.96742e+252 1.99999e+174 7.26588e+223 1.99999e+174 ]]
 [[2.42614e+198 8.04138e-96 9.69724e+189 2.91741e-14 9.47071e-154 ]
  [1.39388e-258 6.16785e+223 1.12648e-153 7.29537e+175 1.44421e+214 ]
  [1.28714e+272 3.25422e+97 7.10583e+159 5.38206e+228 3.06500e+169 ]
  [1.16331e+253 7.36507e+228 2.54716e+151 2.49867e+262 2.68247e-260 ]]]



Total elem: 60
type  : Uint64
cytnx device: CPU
Shape : (3,4,5)
[[[                  0           539784039          1936159329          1869378149          1853187616 ]
  [          168439406           678194281          2036539450          1853127011          1919906670 ]
  [         1663056492           539588709           174419567          1819044198          1663056486 ]
  [         1954112302          1869835877           540699745           695756140          1701736270 ]]
 [[         1818846752           540698220          2036543096          1936614740           980181366 ]
  [          539587681           174419567          1819044198          1663056486          1954112302 ]
  [         1869835877           540699745           757082484           168453486           678194281 ]
  [         2036539450          1853127011          1919906670          1763719788          1310735917 ]]
 [[          539899402          1818587944          2020504697          1412331630          1981820018 ]
  [          695496297          1701736270          1818846752           540698220          2036543096 ]
  [         1936614740           980181366          1043144745           940182117          1932029036 ]
  [         1954112288          2020504697           745697139          1852383290          1867391038 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CUDA/GPU-id:0
Shape : (3,4,5)
[[[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]
 [[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 ]]]





</pre> 
</div>
</div>
<a id="a7b686c6641c3c1eeb2d34cb7c09e433b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b686c6641c3c1eeb2d34cb7c09e433b">&#9670;&nbsp;</a></span>item()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">T&amp; cytnx::Tensor::item </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>get an from a rank-0 <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </p>
<dl class="section return"><dt>Returns</dt><dd>[T]</dd></dl>
<h2>Note:</h2>
<ol type="1">
<li>This can only be called on a rank-0 <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> (scalar). For C++ API, a template instantiation of type is needed to resolve the type, which should be connsist with the dtype of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>. An error will be issued if the template type if inconsist with the current dtype of <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.</li>
<li>Although the return is by reference in C++ part, the return in python is not.</li>
<li>From 2., We recommend user to use at&lt;T&gt; (C++ API) and [] (python API) to modify the value of the element to have consistant syntax across two languages.</li>
</ol>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#a83fb7bbe73368751a0d0f535d4a10a33">ones</a>(1,Type.Uint64);</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">// note that type resolver should be consist with the dtype </span></div><div class="line">    cout &lt;&lt; A.<a class="code" href="classcytnx_1_1Tensor.html#a7b686c6641c3c1eeb2d34cb7c09e433b">item</a>&lt;cytnx_uint64&gt;() &lt;&lt; endl;</div><div class="line">    </div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 1
type  : Uint64
cytnx device: CPU
Shape : (1)
[                  1 ]


1
</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = ones(1,Type.Uint64)</div><div class="line">print(A)</div><div class="line"></div><div class="line">print(A.item())</div><div class="line"></div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 1
type  : Uint64
cytnx device: CPU
Shape : (1)
[                  1 ]



1
</pre> 
</div>
</div>
<a id="adbdc402a8c4d6d738523a888bcf9c0c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adbdc402a8c4d6d738523a888bcf9c0c2">&#9670;&nbsp;</a></span>permute()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> cytnx::Tensor::permute </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; cytnx_uint64 &gt; &amp;&#160;</td>
          <td class="paramname"><em>rnks</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>perform tensor permute on the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">cytnx::Tensor</a> and return a new instance. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnks</td><td>the permute indices, should have No. of elements equal to the rank of tensor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>[<a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>] a permuted new <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a></dd></dl>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A({3,4,5});</div><div class="line">    cout &lt;&lt; A.<a class="code" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>() &lt;&lt; endl;</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = A.<a class="code" href="classcytnx_1_1Tensor.html#adbdc402a8c4d6d738523a888bcf9c0c2">permute</a>({0,2,1});</div><div class="line">    cout &lt;&lt; B.<a class="code" href="classcytnx_1_1Tensor.html#a6d0ab6d09633ad4d6099aa822ec5335a">shape</a>() &lt;&lt; endl;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">Vector Print:
Total Elements:3
[3, 4, 5]

Vector Print:
Total Elements:3
[3, 5, 4]

</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = Tensor([3,4,5])</div><div class="line">print(A.shape())</div><div class="line"></div><div class="line">B = A.permute(0,2,1)</div><div class="line">print(B.shape())</div><div class="line"></div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">[3, 4, 5]
[3, 5, 4]
</pre> 
</div>
</div>
<a id="a182f8f7b3ae3d0db8ed55d2adf8c6b45"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a182f8f7b3ae3d0db8ed55d2adf8c6b45">&#9670;&nbsp;</a></span>reshape()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> cytnx::Tensor::reshape </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; cytnx_int64 &gt; &amp;&#160;</td>
          <td class="paramname"><em>new_shape</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>return a new <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> that is reshaped. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_shape</td><td>the new shape of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>[<a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>]</dd></dl>
<p>See also <a class="el" href="classcytnx_1_1Tensor.html#a3723449528b9a20dd46c32c9e042b8f0">Tensor::reshape_() </a></p>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange</a>(60);</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = A.<a class="code" href="classcytnx_1_1Tensor.html#a182f8f7b3ae3d0db8ed55d2adf8c6b45">reshape</a>({5,12});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line">    cout &lt;&lt; B &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (60)
[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (5,12)
[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 1.00000e+01 1.10000e+01 ]
 [1.20000e+01 1.30000e+01 1.40000e+01 1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 ]
 [2.40000e+01 2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 3.50000e+01 ]
 [3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 4.50000e+01 4.60000e+01 4.70000e+01 ]
 [4.80000e+01 4.90000e+01 5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]


</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = arange(60)</div><div class="line"></div><div class="line">B = A.reshape(5,12)</div><div class="line">print(A)</div><div class="line">print(B)</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (60)
[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (5,12)
[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 1.00000e+01 1.10000e+01 ]
 [1.20000e+01 1.30000e+01 1.40000e+01 1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 ]
 [2.40000e+01 2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 3.50000e+01 ]
 [3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 4.50000e+01 4.60000e+01 4.70000e+01 ]
 [4.80000e+01 4.90000e+01 5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]




</pre> 
</div>
</div>
<a id="a3723449528b9a20dd46c32c9e042b8f0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3723449528b9a20dd46c32c9e042b8f0">&#9670;&nbsp;</a></span>reshape_()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cytnx::Tensor::reshape_ </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; cytnx_int64 &gt; &amp;&#160;</td>
          <td class="paramname"><em>new_shape</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>reshape the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>, inplacely </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">new_shape</td><td>the new shape of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.</td></tr>
  </table>
  </dd>
</dl>
<p>See also <a class="el" href="classcytnx_1_1Tensor.html#a182f8f7b3ae3d0db8ed55d2adf8c6b45">Tensor::reshape() </a></p>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){ </div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange</a>(60);</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    A.<a class="code" href="classcytnx_1_1Tensor.html#a3723449528b9a20dd46c32c9e042b8f0">reshape_</a>({5,12});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (60)
[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (5,12)
[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 1.00000e+01 1.10000e+01 ]
 [1.20000e+01 1.30000e+01 1.40000e+01 1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 ]
 [2.40000e+01 2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 3.50000e+01 ]
 [3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 4.50000e+01 4.60000e+01 4.70000e+01 ]
 [4.80000e+01 4.90000e+01 5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]


</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = arange(60)</div><div class="line">print(A)</div><div class="line">A.reshape_(5,12)</div><div class="line">print(A)</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (60)
[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (5,12)
[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 1.00000e+01 1.10000e+01 ]
 [1.20000e+01 1.30000e+01 1.40000e+01 1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 ]
 [2.40000e+01 2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 3.50000e+01 ]
 [3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 4.50000e+01 4.60000e+01 4.70000e+01 ]
 [4.80000e+01 4.90000e+01 5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]




</pre> 
</div>
</div>
<a id="a771f1f5b51f89abd8df4166e602214ac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a771f1f5b51f89abd8df4166e602214ac">&#9670;&nbsp;</a></span>set() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cytnx::Tensor::set </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="classcytnx_1_1Accessor.html">cytnx::Accessor</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>accessors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>rhs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>set elements with the input <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> using <a class="el" href="classcytnx_1_1Accessor.html" title="object that mimic the python slice to access elements in C++ [this is for c++ API only]...">Accessor</a> (C++ API) / slices (python API) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">accessors</td><td>the list(vector) of accessors. </td></tr>
    <tr><td class="paramname">rhs</td><td>[<a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>]</td></tr>
  </table>
  </dd>
</dl>
<h2>Note:</h2>
<p>the shape of the input <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> should be the same as the shape that indicated using <a class="el" href="classcytnx_1_1Accessor.html" title="object that mimic the python slice to access elements in C++ [this is for c++ API only]...">Accessor</a>. The memory is not shared with the input <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>.</p>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){</div><div class="line"></div><div class="line">    <span class="keyword">typedef</span> <a class="code" href="classcytnx_1_1Accessor.html">Accessor</a> ac;</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange</a>(60).<a class="code" href="classcytnx_1_1Tensor.html#a182f8f7b3ae3d0db8ed55d2adf8c6b45">reshape</a>({3,4,5});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">// 1. Set with Tensor</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = <a class="code" href="namespacecytnx.html#ab8a79a03fb0465f3eb2641017f3f1755">zeros</a>({4,3});</div><div class="line">    cout &lt;&lt; B &lt;&lt; endl;</div><div class="line">    A.<a class="code" href="classcytnx_1_1Tensor.html#a771f1f5b51f89abd8df4166e602214ac">set</a>({ac(2),ac::all(),ac::range(2,5,1)},B);</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">// 2. Set with constant.</span></div><div class="line">    A.<a class="code" href="classcytnx_1_1Tensor.html#a771f1f5b51f89abd8df4166e602214ac">set</a>({ac(0),ac::all(),ac::range(0,2,1)},999);</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 ]
  [4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 ]
  [5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 ]
  [5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]]



Total elem: 12
type  : Double (Float64)
cytnx device: CPU
Shape : (4,3)
[[0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [4.50000e+01 4.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.00000e+01 5.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.50000e+01 5.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[9.99000e+02 9.99000e+02 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [9.99000e+02 9.99000e+02 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [9.99000e+02 9.99000e+02 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [9.99000e+02 9.99000e+02 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [4.50000e+01 4.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.00000e+01 5.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.50000e+01 5.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]]]


</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = arange(60).reshape(3,4,5)</div><div class="line">print(A)</div><div class="line"></div><div class="line">B = zeros([4,3])</div><div class="line">print(B)</div><div class="line"></div><div class="line">A[2,:,2:5:1] = B</div><div class="line">print(A)</div><div class="line"></div><div class="line">A[0,:,0:2:1] = 999</div><div class="line">print(A)</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 ]
  [4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 ]
  [5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 ]
  [5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]]



Total elem: 12
type  : Double (Float64)
cytnx device: CPU
Shape : (4,3)
[[0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [4.50000e+01 4.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.00000e+01 5.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.50000e+01 5.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[9.99000e+02 9.99000e+02 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [9.99000e+02 9.99000e+02 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [9.99000e+02 9.99000e+02 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [9.99000e+02 9.99000e+02 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [4.50000e+01 4.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.00000e+01 5.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.50000e+01 5.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]]]






</pre> 
</div>
</div>
<a id="ad93d654b978add6b2f0dfb9f91490209"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad93d654b978add6b2f0dfb9f91490209">&#9670;&nbsp;</a></span>set() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cytnx::Tensor::set </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="classcytnx_1_1Accessor.html">cytnx::Accessor</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>accessors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>rc</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>set elements with the input constant using <a class="el" href="classcytnx_1_1Accessor.html" title="object that mimic the python slice to access elements in C++ [this is for c++ API only]...">Accessor</a> (C++ API) / slices (python API) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">accessors</td><td>the list(vector) of accessors. </td></tr>
    <tr><td class="paramname">rc</td><td>[Const]</td></tr>
  </table>
  </dd>
</dl>
<p>See also <a class="el" href="classcytnx_1_1Tensor.html#a0c7f2bac2a03be7d22769c7cb896afbe">Tensor::fill </a> for filling all elements with assigned constant.</p>
<h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){</div><div class="line"></div><div class="line">    <span class="keyword">typedef</span> <a class="code" href="classcytnx_1_1Accessor.html">Accessor</a> ac;</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A = <a class="code" href="namespacecytnx.html#a733f9931141463bc8b7c61931ccf52c3">arange</a>(60).<a class="code" href="classcytnx_1_1Tensor.html#a182f8f7b3ae3d0db8ed55d2adf8c6b45">reshape</a>({3,4,5});</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">// 1. Set with Tensor</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = <a class="code" href="namespacecytnx.html#ab8a79a03fb0465f3eb2641017f3f1755">zeros</a>({4,3});</div><div class="line">    cout &lt;&lt; B &lt;&lt; endl;</div><div class="line">    A.<a class="code" href="classcytnx_1_1Tensor.html#a771f1f5b51f89abd8df4166e602214ac">set</a>({ac(2),ac::all(),ac::range(2,5,1)},B);</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="comment">// 2. Set with constant.</span></div><div class="line">    A.<a class="code" href="classcytnx_1_1Tensor.html#a771f1f5b51f89abd8df4166e602214ac">set</a>({ac(0),ac::all(),ac::range(0,2,1)},999);</div><div class="line">    cout &lt;&lt; A &lt;&lt; endl;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 ]
  [4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 ]
  [5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 ]
  [5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]]



Total elem: 12
type  : Double (Float64)
cytnx device: CPU
Shape : (4,3)
[[0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [4.50000e+01 4.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.00000e+01 5.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.50000e+01 5.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[9.99000e+02 9.99000e+02 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [9.99000e+02 9.99000e+02 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [9.99000e+02 9.99000e+02 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [9.99000e+02 9.99000e+02 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [4.50000e+01 4.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.00000e+01 5.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.50000e+01 5.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]]]


</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = arange(60).reshape(3,4,5)</div><div class="line">print(A)</div><div class="line"></div><div class="line">B = zeros([4,3])</div><div class="line">print(B)</div><div class="line"></div><div class="line">A[2,:,2:5:1] = B</div><div class="line">print(A)</div><div class="line"></div><div class="line">A[0,:,0:2:1] = 999</div><div class="line">print(A)</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">
Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 4.20000e+01 4.30000e+01 4.40000e+01 ]
  [4.50000e+01 4.60000e+01 4.70000e+01 4.80000e+01 4.90000e+01 ]
  [5.00000e+01 5.10000e+01 5.20000e+01 5.30000e+01 5.40000e+01 ]
  [5.50000e+01 5.60000e+01 5.70000e+01 5.80000e+01 5.90000e+01 ]]]



Total elem: 12
type  : Double (Float64)
cytnx device: CPU
Shape : (4,3)
[[0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]
 [0.00000e+00 0.00000e+00 0.00000e+00 ]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[0.00000e+00 1.00000e+00 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [5.00000e+00 6.00000e+00 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [1.00000e+01 1.10000e+01 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [1.50000e+01 1.60000e+01 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [4.50000e+01 4.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.00000e+01 5.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.50000e+01 5.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]]]



Total elem: 60
type  : Double (Float64)
cytnx device: CPU
Shape : (3,4,5)
[[[9.99000e+02 9.99000e+02 2.00000e+00 3.00000e+00 4.00000e+00 ]
  [9.99000e+02 9.99000e+02 7.00000e+00 8.00000e+00 9.00000e+00 ]
  [9.99000e+02 9.99000e+02 1.20000e+01 1.30000e+01 1.40000e+01 ]
  [9.99000e+02 9.99000e+02 1.70000e+01 1.80000e+01 1.90000e+01 ]]
 [[2.00000e+01 2.10000e+01 2.20000e+01 2.30000e+01 2.40000e+01 ]
  [2.50000e+01 2.60000e+01 2.70000e+01 2.80000e+01 2.90000e+01 ]
  [3.00000e+01 3.10000e+01 3.20000e+01 3.30000e+01 3.40000e+01 ]
  [3.50000e+01 3.60000e+01 3.70000e+01 3.80000e+01 3.90000e+01 ]]
 [[4.00000e+01 4.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [4.50000e+01 4.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.00000e+01 5.10000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]
  [5.50000e+01 5.60000e+01 0.00000e+00 0.00000e+00 0.00000e+00 ]]]






</pre> 
</div>
</div>
<a id="a6d0ab6d09633ad4d6099aa822ec5335a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6d0ab6d09633ad4d6099aa822ec5335a">&#9670;&nbsp;</a></span>shape()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const std::vector&lt;cytnx_uint64&gt;&amp; cytnx::Tensor::shape </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>the shape of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </p>
<dl class="section return"><dt>Returns</dt><dd>[std::vector&lt;cytnx_uint64&gt;] the shape of the <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> </dd></dl>

</div>
</div>
<a id="a0fd5918a0f64ebd74fe34cb8b8164c30"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0fd5918a0f64ebd74fe34cb8b8164c30">&#9670;&nbsp;</a></span>storage()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcytnx_1_1Storage.html">Storage</a>&amp; cytnx::Tensor::storage </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>return the storage of current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>[<a class="el" href="classcytnx_1_1Storage.html" title="an memeory storage with multi-type/multi-device support ">Storage</a>]</dd></dl>
<h2>Note:</h2>
<ol type="1">
<li>The return storage shares the same instance of the storage of current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>. Use <a class="el" href="classcytnx_1_1Storage.html#aed0530dd20f3fb352d45653ba46a3d50">Storage.clone() </a> to create a new instance of the returned <a class="el" href="classcytnx_1_1Storage.html" title="an memeory storage with multi-type/multi-device support ">Storage</a>. </li>
</ol>

</div>
</div>
<a id="acf7f697a9434f9bc98a7d00a555ee982"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf7f697a9434f9bc98a7d00a555ee982">&#9670;&nbsp;</a></span>to()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcytnx_1_1Tensor.html">Tensor</a> cytnx::Tensor::to </td>
          <td>(</td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>device</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>copy a tensor to new device </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device</td><td>the device-id that is moving to. it can be any device defined in cytnx::Device </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>[<a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>]</dd></dl>
<p>description:<br />
 if the device-id is the same as current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a>'s device, then return self.<br />
 otherwise, return a copy of instance that located on the target device. <br />
 see also: <a class="el" href="classcytnx_1_1Tensor.html#a114a31fbb8bf4a90f150b6a67e42183a">Tensor.to_ </a> <br />
 </p><h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A({3,4,5});</div><div class="line"></div><div class="line">    <span class="comment">//move the tensor to different device by creating a clone object</span></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> B = A.<a class="code" href="classcytnx_1_1Tensor.html#acf7f697a9434f9bc98a7d00a555ee982">to</a>(Device.cuda+0);</div><div class="line">    cout &lt;&lt; B.<a class="code" href="classcytnx_1_1Tensor.html#a335f7625fa01784f49b2223238d0c14e">device_str</a>() &lt;&lt; endl;</div><div class="line">    cout &lt;&lt; A.<a class="code" href="classcytnx_1_1Tensor.html#a335f7625fa01784f49b2223238d0c14e">device_str</a>() &lt;&lt; endl;    </div><div class="line"></div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">cytnx device: CUDA/GPU-id:0
cytnx device: CPU
</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = Tensor([3,4,5])</div><div class="line">B = A.to(Device.cuda+0);</div><div class="line">print(B.device_str())</div><div class="line">print(A.device_str())</div><div class="line"></div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">cytnx device: CUDA/GPU-id:0
cytnx device: CPU
</pre> 
</div>
</div>
<a id="a114a31fbb8bf4a90f150b6a67e42183a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a114a31fbb8bf4a90f150b6a67e42183a">&#9670;&nbsp;</a></span>to_()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void cytnx::Tensor::to_ </td>
          <td>(</td>
          <td class="paramtype">const int &amp;&#160;</td>
          <td class="paramname"><em>device</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>move the current <a class="el" href="classcytnx_1_1Tensor.html" title="an tensor (multi-dimensional array) ">Tensor</a> to the device. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device</td><td>the device-id that is moving to. it can be any device defined in cytnx::Device</td></tr>
  </table>
  </dd>
</dl>
<p>description:<br />
 see also: <a class="el" href="classcytnx_1_1Tensor.html#acf7f697a9434f9bc98a7d00a555ee982">Tensor.to </a><br />
 </p><h2>Example:</h2>
<h3>c++ API:</h3>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;cytnx.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecytnx.html">cytnx</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"><span class="keywordtype">int</span> main(){</div><div class="line"></div><div class="line">    <a class="code" href="classcytnx_1_1Tensor.html">Tensor</a> A({3,4,5});</div><div class="line"></div><div class="line">    <span class="comment">// move the instance tensor to different device</span></div><div class="line">    A.<a class="code" href="classcytnx_1_1Tensor.html#a114a31fbb8bf4a90f150b6a67e42183a">to_</a>(Device.cuda+0);</div><div class="line">    cout &lt;&lt; A.<a class="code" href="classcytnx_1_1Tensor.html#a335f7625fa01784f49b2223238d0c14e">device_str</a>() &lt;&lt; endl;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">cytnx device: CUDA/GPU-id:0
</pre> <h3>python API:</h3>
<div class="fragment"><div class="line"><span class="keyword">from</span> cytnx <span class="keyword">import</span> *</div><div class="line"></div><div class="line">A = Tensor([3,4,5])</div><div class="line"></div><div class="line">A.to_(Device.cuda+0);</div><div class="line">print(A.device_str())</div><div class="line"></div></div><!-- fragment --> <h4>output&gt;</h4>
<pre class="fragment">cytnx device: CUDA/GPU-id:0
</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>include/<a class="el" href="Tensor_8hpp_source.html">Tensor.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
